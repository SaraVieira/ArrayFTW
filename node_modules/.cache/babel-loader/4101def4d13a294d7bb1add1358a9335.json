{"ast":null,"code":"import { Vector3, Vector2 } from 'three';\n/**\n * Shaders to render 3D volumes using raycasting.\n * The applied techniques are based on similar implementations in the Visvis and Vispy projects.\n * This is not the only approach, therefore it's marked 1.\n */\n\nvar VolumeRenderShader1 = {\n  uniforms: {\n    u_size: {\n      value: new Vector3(1, 1, 1)\n    },\n    u_renderstyle: {\n      value: 0\n    },\n    u_renderthreshold: {\n      value: 0.5\n    },\n    u_clim: {\n      value: new Vector2(1, 1)\n    },\n    u_data: {\n      value: null\n    },\n    u_cmdata: {\n      value: null\n    }\n  },\n  vertexShader: ['\t\tvarying vec4 v_nearpos;', '\t\tvarying vec4 v_farpos;', '\t\tvarying vec3 v_position;', '\t\tvoid main() {', // Prepare transforms to map to \"camera view\". See also:\n  // https://threejs.org/docs/#api/renderers/webgl/WebGLProgram\n  '\t\t\t\tmat4 viewtransformf = modelViewMatrix;', '\t\t\t\tmat4 viewtransformi = inverse(modelViewMatrix);', // Project local vertex coordinate to camera position. Then do a step\n  // backward (in cam coords) to the near clipping plane, and project back. Do\n  // the same for the far clipping plane. This gives us all the information we\n  // need to calculate the ray and truncate it to the viewing cone.\n  '\t\t\t\tvec4 position4 = vec4(position, 1.0);', '\t\t\t\tvec4 pos_in_cam = viewtransformf * position4;', // Intersection of ray and near clipping plane (z = -1 in clip coords)\n  '\t\t\t\tpos_in_cam.z = -pos_in_cam.w;', '\t\t\t\tv_nearpos = viewtransformi * pos_in_cam;', // Intersection of ray and far clipping plane (z = +1 in clip coords)\n  '\t\t\t\tpos_in_cam.z = pos_in_cam.w;', '\t\t\t\tv_farpos = viewtransformi * pos_in_cam;', // Set varyings and output pos\n  '\t\t\t\tv_position = position;', '\t\t\t\tgl_Position = projectionMatrix * viewMatrix * modelMatrix * position4;', '\t\t}'].join('\\n'),\n  fragmentShader: ['\t\tprecision highp float;', '\t\tprecision mediump sampler3D;', '\t\tuniform vec3 u_size;', '\t\tuniform int u_renderstyle;', '\t\tuniform float u_renderthreshold;', '\t\tuniform vec2 u_clim;', '\t\tuniform sampler3D u_data;', '\t\tuniform sampler2D u_cmdata;', '\t\tvarying vec3 v_position;', '\t\tvarying vec4 v_nearpos;', '\t\tvarying vec4 v_farpos;', // The maximum distance through our rendering volume is sqrt(3).\n  '\t\tconst int MAX_STEPS = 887;\t// 887 for 512^3, 1774 for 1024^3', '\t\tconst int REFINEMENT_STEPS = 4;', '\t\tconst float relative_step_size = 1.0;', '\t\tconst vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);', '\t\tconst vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);', '\t\tconst vec4 specular_color = vec4(1.0, 1.0, 1.0, 1.0);', '\t\tconst float shininess = 40.0;', '\t\tvoid cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);', '\t\tvoid cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);', '\t\tfloat sample1(vec3 texcoords);', '\t\tvec4 apply_colormap(float val);', '\t\tvec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray);', '\t\tvoid main() {', // Normalize clipping plane info\n  '\t\t\t\tvec3 farpos = v_farpos.xyz / v_farpos.w;', '\t\t\t\tvec3 nearpos = v_nearpos.xyz / v_nearpos.w;', // Calculate unit vector pointing in the view direction through this fragment.\n  '\t\t\t\tvec3 view_ray = normalize(nearpos.xyz - farpos.xyz);', // Compute the (negative) distance to the front surface or near clipping plane.\n  // v_position is the back face of the cuboid, so the initial distance calculated in the dot\n  // product below is the distance from near clip plane to the back of the cuboid\n  '\t\t\t\tfloat distance = dot(nearpos - v_position, view_ray);', '\t\t\t\tdistance = max(distance, min((-0.5 - v_position.x) / view_ray.x,', '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.x - 0.5 - v_position.x) / view_ray.x));', '\t\t\t\tdistance = max(distance, min((-0.5 - v_position.y) / view_ray.y,', '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.y - 0.5 - v_position.y) / view_ray.y));', '\t\t\t\tdistance = max(distance, min((-0.5 - v_position.z) / view_ray.z,', '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.z - 0.5 - v_position.z) / view_ray.z));', // Now we have the starting position on the front surface\n  '\t\t\t\tvec3 front = v_position + view_ray * distance;', // Decide how many steps to take\n  '\t\t\t\tint nsteps = int(-distance / relative_step_size + 0.5);', '\t\t\t\tif ( nsteps < 1 )', '\t\t\t\t\t\tdiscard;', // Get starting location and step vector in texture coordinates\n  '\t\t\t\tvec3 step = ((v_position - front) / u_size) / float(nsteps);', '\t\t\t\tvec3 start_loc = front / u_size;', // For testing: show the number of steps. This helps to establish\n  // whether the rays are correctly oriented\n  //'gl_FragColor = vec4(0.0, float(nsteps) / 1.0 / u_size.x, 1.0, 1.0);',\n  //'return;',\n  '\t\t\t\tif (u_renderstyle == 0)', '\t\t\t\t\t\tcast_mip(start_loc, step, nsteps, view_ray);', '\t\t\t\telse if (u_renderstyle == 1)', '\t\t\t\t\t\tcast_iso(start_loc, step, nsteps, view_ray);', '\t\t\t\tif (gl_FragColor.a < 0.05)', '\t\t\t\t\t\tdiscard;', '\t\t}', '\t\tfloat sample1(vec3 texcoords) {', '\t\t\t\t/* Sample float value from a 3D texture. Assumes intensity data. */', '\t\t\t\treturn texture(u_data, texcoords.xyz).r;', '\t\t}', '\t\tvec4 apply_colormap(float val) {', '\t\t\t\tval = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);', '\t\t\t\treturn texture2D(u_cmdata, vec2(val, 0.5));', '\t\t}', '\t\tvoid cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {', '\t\t\t\tfloat max_val = -1e6;', '\t\t\t\tint max_i = 100;', '\t\t\t\tvec3 loc = start_loc;', // Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with\n  // non-constant expression. So we use a hard-coded max, and an additional condition\n  // inside the loop.\n  '\t\t\t\tfor (int iter=0; iter<MAX_STEPS; iter++) {', '\t\t\t\t\t\tif (iter >= nsteps)', '\t\t\t\t\t\t\t\tbreak;', // Sample from the 3D texture\n  '\t\t\t\t\t\tfloat val = sample1(loc);', // Apply MIP operation\n  '\t\t\t\t\t\tif (val > max_val) {', '\t\t\t\t\t\t\t\tmax_val = val;', '\t\t\t\t\t\t\t\tmax_i = iter;', '\t\t\t\t\t\t}', // Advance location deeper into the volume\n  '\t\t\t\t\t\tloc += step;', '\t\t\t\t}', // Refine location, gives crispier images\n  '\t\t\t\tvec3 iloc = start_loc + step * (float(max_i) - 0.5);', '\t\t\t\tvec3 istep = step / float(REFINEMENT_STEPS);', '\t\t\t\tfor (int i=0; i<REFINEMENT_STEPS; i++) {', '\t\t\t\t\t\tmax_val = max(max_val, sample1(iloc));', '\t\t\t\t\t\tiloc += istep;', '\t\t\t\t}', // Resolve final color\n  '\t\t\t\tgl_FragColor = apply_colormap(max_val);', '\t\t}', '\t\tvoid cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {', '\t\t\t\tgl_FragColor = vec4(0.0);\t// init transparent', '\t\t\t\tvec4 color3 = vec4(0.0);\t// final color', '\t\t\t\tvec3 dstep = 1.5 / u_size;\t// step to sample derivative', '\t\t\t\tvec3 loc = start_loc;', '\t\t\t\tfloat low_threshold = u_renderthreshold - 0.02 * (u_clim[1] - u_clim[0]);', // Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with\n  // non-constant expression. So we use a hard-coded max, and an additional condition\n  // inside the loop.\n  '\t\t\t\tfor (int iter=0; iter<MAX_STEPS; iter++) {', '\t\t\t\t\t\tif (iter >= nsteps)', '\t\t\t\t\t\t\t\tbreak;', // Sample from the 3D texture\n  '\t\t\t\t\t\tfloat val = sample1(loc);', '\t\t\t\t\t\tif (val > low_threshold) {', // Take the last interval in smaller steps\n  '\t\t\t\t\t\t\t\tvec3 iloc = loc - 0.5 * step;', '\t\t\t\t\t\t\t\tvec3 istep = step / float(REFINEMENT_STEPS);', '\t\t\t\t\t\t\t\tfor (int i=0; i<REFINEMENT_STEPS; i++) {', '\t\t\t\t\t\t\t\t\t\tval = sample1(iloc);', '\t\t\t\t\t\t\t\t\t\tif (val > u_renderthreshold) {', '\t\t\t\t\t\t\t\t\t\t\t\tgl_FragColor = add_lighting(val, iloc, dstep, view_ray);', '\t\t\t\t\t\t\t\t\t\t\t\treturn;', '\t\t\t\t\t\t\t\t\t\t}', '\t\t\t\t\t\t\t\t\t\tiloc += istep;', '\t\t\t\t\t\t\t\t}', '\t\t\t\t\t\t}', // Advance location deeper into the volume\n  '\t\t\t\t\t\tloc += step;', '\t\t\t\t}', '\t\t}', '\t\tvec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray)', '\t\t{', // Calculate color by incorporating lighting\n  // View direction\n  '\t\t\t\tvec3 V = normalize(view_ray);', // calculate normal vector from gradient\n  '\t\t\t\tvec3 N;', '\t\t\t\tfloat val1, val2;', '\t\t\t\tval1 = sample1(loc + vec3(-step[0], 0.0, 0.0));', '\t\t\t\tval2 = sample1(loc + vec3(+step[0], 0.0, 0.0));', '\t\t\t\tN[0] = val1 - val2;', '\t\t\t\tval = max(max(val1, val2), val);', '\t\t\t\tval1 = sample1(loc + vec3(0.0, -step[1], 0.0));', '\t\t\t\tval2 = sample1(loc + vec3(0.0, +step[1], 0.0));', '\t\t\t\tN[1] = val1 - val2;', '\t\t\t\tval = max(max(val1, val2), val);', '\t\t\t\tval1 = sample1(loc + vec3(0.0, 0.0, -step[2]));', '\t\t\t\tval2 = sample1(loc + vec3(0.0, 0.0, +step[2]));', '\t\t\t\tN[2] = val1 - val2;', '\t\t\t\tval = max(max(val1, val2), val);', '\t\t\t\tfloat gm = length(N); // gradient magnitude', '\t\t\t\tN = normalize(N);', // Flip normal so it points towards viewer\n  '\t\t\t\tfloat Nselect = float(dot(N, V) > 0.0);', '\t\t\t\tN = (2.0 * Nselect - 1.0) * N;\t// ==\tNselect * N - (1.0-Nselect)*N;', // Init colors\n  '\t\t\t\tvec4 ambient_color = vec4(0.0, 0.0, 0.0, 0.0);', '\t\t\t\tvec4 diffuse_color = vec4(0.0, 0.0, 0.0, 0.0);', '\t\t\t\tvec4 specular_color = vec4(0.0, 0.0, 0.0, 0.0);', // note: could allow multiple lights\n  '\t\t\t\tfor (int i=0; i<1; i++)', '\t\t\t\t{', // Get light direction (make sure to prevent zero devision)\n  '\t\t\t\t\t\tvec3 L = normalize(view_ray);\t//lightDirs[i];', '\t\t\t\t\t\tfloat lightEnabled = float( length(L) > 0.0 );', '\t\t\t\t\t\tL = normalize(L + (1.0 - lightEnabled));', // Calculate lighting properties\n  '\t\t\t\t\t\tfloat lambertTerm = clamp(dot(N, L), 0.0, 1.0);', '\t\t\t\t\t\tvec3 H = normalize(L+V); // Halfway vector', '\t\t\t\t\t\tfloat specularTerm = pow(max(dot(H, N), 0.0), shininess);', // Calculate mask\n  '\t\t\t\t\t\tfloat mask1 = lightEnabled;', // Calculate colors\n  '\t\t\t\t\t\tambient_color +=\tmask1 * ambient_color;\t// * gl_LightSource[i].ambient;', '\t\t\t\t\t\tdiffuse_color +=\tmask1 * lambertTerm;', '\t\t\t\t\t\tspecular_color += mask1 * specularTerm * specular_color;', '\t\t\t\t}', // Calculate final color by componing different components\n  '\t\t\t\tvec4 final_color;', '\t\t\t\tvec4 color = apply_colormap(val);', '\t\t\t\tfinal_color = color * (ambient_color + diffuse_color) + specular_color;', '\t\t\t\tfinal_color.a = color.a;', '\t\t\t\treturn final_color;', '\t\t}'].join('\\n')\n};\nexport { VolumeRenderShader1 };","map":{"version":3,"sources":["/Projects/arrayftw/node_modules/three-stdlib/shaders/VolumeShader.js"],"names":["Vector3","Vector2","VolumeRenderShader1","uniforms","u_size","value","u_renderstyle","u_renderthreshold","u_clim","u_data","u_cmdata","vertexShader","join","fragmentShader"],"mappings":"AAAA,SAASA,OAAT,EAAkBC,OAAlB,QAAiC,OAAjC;AAEA;AACA;AACA;AACA;AACA;;AAEA,IAAIC,mBAAmB,GAAG;AACxBC,EAAAA,QAAQ,EAAE;AACRC,IAAAA,MAAM,EAAE;AACNC,MAAAA,KAAK,EAAE,IAAIL,OAAJ,CAAY,CAAZ,EAAe,CAAf,EAAkB,CAAlB;AADD,KADA;AAIRM,IAAAA,aAAa,EAAE;AACbD,MAAAA,KAAK,EAAE;AADM,KAJP;AAORE,IAAAA,iBAAiB,EAAE;AACjBF,MAAAA,KAAK,EAAE;AADU,KAPX;AAURG,IAAAA,MAAM,EAAE;AACNH,MAAAA,KAAK,EAAE,IAAIJ,OAAJ,CAAY,CAAZ,EAAe,CAAf;AADD,KAVA;AAaRQ,IAAAA,MAAM,EAAE;AACNJ,MAAAA,KAAK,EAAE;AADD,KAbA;AAgBRK,IAAAA,QAAQ,EAAE;AACRL,MAAAA,KAAK,EAAE;AADC;AAhBF,GADc;AAqBxBM,EAAAA,YAAY,EAAE,CAAC,2BAAD,EAA8B,0BAA9B,EAA0D,4BAA1D,EAAwF,iBAAxF,EAA2G;AACzH;AACA,8CAFc,EAEgC,qDAFhC,EAEuF;AACrG;AACA;AACA;AACA,6CANc,EAM+B,mDAN/B,EAMoF;AAClG,qCAPc,EAOuB,8CAPvB,EAOuE;AACrF,oCARc,EAQsB,6CARtB,EAQqE;AACnF,8BATc,EASgB,4EAThB,EAS8F,KAT9F,EASqGC,IATrG,CAS0G,IAT1G,CArBU;AA+BxBC,EAAAA,cAAc,EAAE,CAAC,0BAAD,EAA6B,gCAA7B,EAA+D,wBAA/D,EAAyF,8BAAzF,EAAyH,oCAAzH,EAA+J,wBAA/J,EAAyL,6BAAzL,EAAwN,+BAAxN,EAAyP,4BAAzP,EAAuR,2BAAvR,EAAoT,0BAApT,EAAgV;AAChW,kEADgB,EACkD,mCADlD,EACuF,yCADvF,EACkI,wDADlI,EAC4L,wDAD5L,EACsP,yDADtP,EACiT,iCADjT,EACoV,wEADpV,EAC8Z,wEAD9Z,EACwe,kCADxe,EAC4gB,mCAD5gB,EACijB,qEADjjB,EACwnB,iBADxnB,EAC2oB;AAC3pB,gDAFgB,EAEgC,iDAFhC,EAEmF;AACnG,4DAHgB,EAG4C;AAC5D;AACA;AACA,6DANgB,EAM6C,sEAN7C,EAMqH,mEANrH,EAM0L,sEAN1L,EAMkQ,mEANlQ,EAMuU,sEANvU,EAM+Y,mEAN/Y,EAMod;AACpe,sDAPgB,EAOsC;AACtD,+DARgB,EAQ+C,uBAR/C,EAQwE,gBARxE,EAQ0F;AAC1G,oEATgB,EASoD,sCATpD,EAS4F;AAC5G;AACA;AACA;AACA,+BAbgB,EAae,oDAbf,EAaqE,kCAbrE,EAayG,oDAbzG,EAa+J,gCAb/J,EAaiM,gBAbjM,EAamN,KAbnN,EAa0N,mCAb1N,EAa+P,yEAb/P,EAa0U,8CAb1U,EAa0X,KAb1X,EAaiY,oCAbjY,EAaua,wDAbva,EAaie,iDAbje,EAaohB,KAbphB,EAa2hB,yEAb3hB,EAasmB,2BAbtmB,EAamoB,sBAbnoB,EAa2pB,2BAb3pB,EAawrB;AACxsB;AACA;AACA,kDAhBgB,EAgBkC,2BAhBlC,EAgB+D,gBAhB/D,EAgBiF;AACjG,mCAjBgB,EAiBmB;AACnC,8BAlBgB,EAkBc,wBAlBd,EAkBwC,uBAlBxC,EAkBiE,SAlBjE,EAkB4E;AAC5F,sBAnBgB,EAmBM,OAnBN,EAmBe;AAC/B,4DApBgB,EAoB4C,kDApB5C,EAoBgG,8CApBhG,EAoBgJ,8CApBhJ,EAoBgM,sBApBhM,EAoBwN,OApBxN,EAoBiO;AACjP,+CArBgB,EAqB+B,KArB/B,EAqBsC,yEArBtC,EAqBiH,mDArBjH,EAqBsK,6CArBtK,EAqBqN,6DArBrN,EAqBoR,2BArBpR,EAqBiT,+EArBjT,EAqBkY;AAClZ;AACA;AACA,kDAxBgB,EAwBkC,2BAxBlC,EAwB+D,gBAxB/D,EAwBiF;AACjG,mCAzBgB,EAyBmB,kCAzBnB,EAyBuD;AACvE,yCA1BgB,EA0ByB,sDA1BzB,EA0BiF,kDA1BjF,EA0BqI,gCA1BrI,EA0BuK,0CA1BvK,EA0BmN,sEA1BnN,EA0B2R,qBA1B3R,EA0BkT,aA1BlT,EA0BiU,0BA1BjU,EA0B6V,WA1B7V,EA0B0W,SA1B1W,EA0BqX;AACrY,sBA3BgB,EA2BM,OA3BN,EA2Be,KA3Bf,EA2BsB,oEA3BtB,EA2B4F,KA3B5F,EA2BmG;AACnH;AACA,qCA7BgB,EA6BqB;AACrC,eA9BgB,EA8BD,uBA9BC,EA8BwB,qDA9BxB,EA8B+E,qDA9B/E,EA8BsI,yBA9BtI,EA8BiK,sCA9BjK,EA8ByM,qDA9BzM,EA8BgQ,qDA9BhQ,EA8BuT,yBA9BvT,EA8BkV,sCA9BlV,EA8B0X,qDA9B1X,EA8Bib,qDA9Bjb,EA8Bwe,yBA9Bxe,EA8BmgB,sCA9BngB,EA8B2iB,iDA9B3iB,EA8B8lB,uBA9B9lB,EA8BunB;AACvoB,+CA/BgB,EA+B+B,yEA/B/B,EA+B0G;AAC1H,sDAhCgB,EAgCsC,oDAhCtC,EAgC4F,qDAhC5F,EAgCmJ;AACnK,+BAjCgB,EAiCe,OAjCf,EAiCwB;AACxC,uDAlCgB,EAkCuC,sDAlCvC,EAkC+F,gDAlC/F,EAkCiJ;AACjK,yDAnCgB,EAmCyC,kDAnCzC,EAmC6F,iEAnC7F,EAmCgK;AAChL,qCApCgB,EAoCqB;AACrC,iFArCgB,EAqCiE,6CArCjE,EAqCgH,gEArChH,EAqCkL,OArClL,EAqC2L;AAC3M,yBAtCgB,EAsCS,uCAtCT,EAsCkD,6EAtClD,EAsCiI,8BAtCjI,EAsCiK,yBAtCjK,EAsC4L,KAtC5L,EAsCmMD,IAtCnM,CAsCwM,IAtCxM;AA/BQ,CAA1B;AAwEA,SAASV,mBAAT","sourcesContent":["import { Vector3, Vector2 } from 'three';\n\n/**\n * Shaders to render 3D volumes using raycasting.\n * The applied techniques are based on similar implementations in the Visvis and Vispy projects.\n * This is not the only approach, therefore it's marked 1.\n */\n\nvar VolumeRenderShader1 = {\n  uniforms: {\n    u_size: {\n      value: new Vector3(1, 1, 1)\n    },\n    u_renderstyle: {\n      value: 0\n    },\n    u_renderthreshold: {\n      value: 0.5\n    },\n    u_clim: {\n      value: new Vector2(1, 1)\n    },\n    u_data: {\n      value: null\n    },\n    u_cmdata: {\n      value: null\n    }\n  },\n  vertexShader: ['\t\tvarying vec4 v_nearpos;', '\t\tvarying vec4 v_farpos;', '\t\tvarying vec3 v_position;', '\t\tvoid main() {', // Prepare transforms to map to \"camera view\". See also:\n  // https://threejs.org/docs/#api/renderers/webgl/WebGLProgram\n  '\t\t\t\tmat4 viewtransformf = modelViewMatrix;', '\t\t\t\tmat4 viewtransformi = inverse(modelViewMatrix);', // Project local vertex coordinate to camera position. Then do a step\n  // backward (in cam coords) to the near clipping plane, and project back. Do\n  // the same for the far clipping plane. This gives us all the information we\n  // need to calculate the ray and truncate it to the viewing cone.\n  '\t\t\t\tvec4 position4 = vec4(position, 1.0);', '\t\t\t\tvec4 pos_in_cam = viewtransformf * position4;', // Intersection of ray and near clipping plane (z = -1 in clip coords)\n  '\t\t\t\tpos_in_cam.z = -pos_in_cam.w;', '\t\t\t\tv_nearpos = viewtransformi * pos_in_cam;', // Intersection of ray and far clipping plane (z = +1 in clip coords)\n  '\t\t\t\tpos_in_cam.z = pos_in_cam.w;', '\t\t\t\tv_farpos = viewtransformi * pos_in_cam;', // Set varyings and output pos\n  '\t\t\t\tv_position = position;', '\t\t\t\tgl_Position = projectionMatrix * viewMatrix * modelMatrix * position4;', '\t\t}'].join('\\n'),\n  fragmentShader: ['\t\tprecision highp float;', '\t\tprecision mediump sampler3D;', '\t\tuniform vec3 u_size;', '\t\tuniform int u_renderstyle;', '\t\tuniform float u_renderthreshold;', '\t\tuniform vec2 u_clim;', '\t\tuniform sampler3D u_data;', '\t\tuniform sampler2D u_cmdata;', '\t\tvarying vec3 v_position;', '\t\tvarying vec4 v_nearpos;', '\t\tvarying vec4 v_farpos;', // The maximum distance through our rendering volume is sqrt(3).\n  '\t\tconst int MAX_STEPS = 887;\t// 887 for 512^3, 1774 for 1024^3', '\t\tconst int REFINEMENT_STEPS = 4;', '\t\tconst float relative_step_size = 1.0;', '\t\tconst vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);', '\t\tconst vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);', '\t\tconst vec4 specular_color = vec4(1.0, 1.0, 1.0, 1.0);', '\t\tconst float shininess = 40.0;', '\t\tvoid cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);', '\t\tvoid cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);', '\t\tfloat sample1(vec3 texcoords);', '\t\tvec4 apply_colormap(float val);', '\t\tvec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray);', '\t\tvoid main() {', // Normalize clipping plane info\n  '\t\t\t\tvec3 farpos = v_farpos.xyz / v_farpos.w;', '\t\t\t\tvec3 nearpos = v_nearpos.xyz / v_nearpos.w;', // Calculate unit vector pointing in the view direction through this fragment.\n  '\t\t\t\tvec3 view_ray = normalize(nearpos.xyz - farpos.xyz);', // Compute the (negative) distance to the front surface or near clipping plane.\n  // v_position is the back face of the cuboid, so the initial distance calculated in the dot\n  // product below is the distance from near clip plane to the back of the cuboid\n  '\t\t\t\tfloat distance = dot(nearpos - v_position, view_ray);', '\t\t\t\tdistance = max(distance, min((-0.5 - v_position.x) / view_ray.x,', '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.x - 0.5 - v_position.x) / view_ray.x));', '\t\t\t\tdistance = max(distance, min((-0.5 - v_position.y) / view_ray.y,', '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.y - 0.5 - v_position.y) / view_ray.y));', '\t\t\t\tdistance = max(distance, min((-0.5 - v_position.z) / view_ray.z,', '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.z - 0.5 - v_position.z) / view_ray.z));', // Now we have the starting position on the front surface\n  '\t\t\t\tvec3 front = v_position + view_ray * distance;', // Decide how many steps to take\n  '\t\t\t\tint nsteps = int(-distance / relative_step_size + 0.5);', '\t\t\t\tif ( nsteps < 1 )', '\t\t\t\t\t\tdiscard;', // Get starting location and step vector in texture coordinates\n  '\t\t\t\tvec3 step = ((v_position - front) / u_size) / float(nsteps);', '\t\t\t\tvec3 start_loc = front / u_size;', // For testing: show the number of steps. This helps to establish\n  // whether the rays are correctly oriented\n  //'gl_FragColor = vec4(0.0, float(nsteps) / 1.0 / u_size.x, 1.0, 1.0);',\n  //'return;',\n  '\t\t\t\tif (u_renderstyle == 0)', '\t\t\t\t\t\tcast_mip(start_loc, step, nsteps, view_ray);', '\t\t\t\telse if (u_renderstyle == 1)', '\t\t\t\t\t\tcast_iso(start_loc, step, nsteps, view_ray);', '\t\t\t\tif (gl_FragColor.a < 0.05)', '\t\t\t\t\t\tdiscard;', '\t\t}', '\t\tfloat sample1(vec3 texcoords) {', '\t\t\t\t/* Sample float value from a 3D texture. Assumes intensity data. */', '\t\t\t\treturn texture(u_data, texcoords.xyz).r;', '\t\t}', '\t\tvec4 apply_colormap(float val) {', '\t\t\t\tval = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);', '\t\t\t\treturn texture2D(u_cmdata, vec2(val, 0.5));', '\t\t}', '\t\tvoid cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {', '\t\t\t\tfloat max_val = -1e6;', '\t\t\t\tint max_i = 100;', '\t\t\t\tvec3 loc = start_loc;', // Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with\n  // non-constant expression. So we use a hard-coded max, and an additional condition\n  // inside the loop.\n  '\t\t\t\tfor (int iter=0; iter<MAX_STEPS; iter++) {', '\t\t\t\t\t\tif (iter >= nsteps)', '\t\t\t\t\t\t\t\tbreak;', // Sample from the 3D texture\n  '\t\t\t\t\t\tfloat val = sample1(loc);', // Apply MIP operation\n  '\t\t\t\t\t\tif (val > max_val) {', '\t\t\t\t\t\t\t\tmax_val = val;', '\t\t\t\t\t\t\t\tmax_i = iter;', '\t\t\t\t\t\t}', // Advance location deeper into the volume\n  '\t\t\t\t\t\tloc += step;', '\t\t\t\t}', // Refine location, gives crispier images\n  '\t\t\t\tvec3 iloc = start_loc + step * (float(max_i) - 0.5);', '\t\t\t\tvec3 istep = step / float(REFINEMENT_STEPS);', '\t\t\t\tfor (int i=0; i<REFINEMENT_STEPS; i++) {', '\t\t\t\t\t\tmax_val = max(max_val, sample1(iloc));', '\t\t\t\t\t\tiloc += istep;', '\t\t\t\t}', // Resolve final color\n  '\t\t\t\tgl_FragColor = apply_colormap(max_val);', '\t\t}', '\t\tvoid cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {', '\t\t\t\tgl_FragColor = vec4(0.0);\t// init transparent', '\t\t\t\tvec4 color3 = vec4(0.0);\t// final color', '\t\t\t\tvec3 dstep = 1.5 / u_size;\t// step to sample derivative', '\t\t\t\tvec3 loc = start_loc;', '\t\t\t\tfloat low_threshold = u_renderthreshold - 0.02 * (u_clim[1] - u_clim[0]);', // Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with\n  // non-constant expression. So we use a hard-coded max, and an additional condition\n  // inside the loop.\n  '\t\t\t\tfor (int iter=0; iter<MAX_STEPS; iter++) {', '\t\t\t\t\t\tif (iter >= nsteps)', '\t\t\t\t\t\t\t\tbreak;', // Sample from the 3D texture\n  '\t\t\t\t\t\tfloat val = sample1(loc);', '\t\t\t\t\t\tif (val > low_threshold) {', // Take the last interval in smaller steps\n  '\t\t\t\t\t\t\t\tvec3 iloc = loc - 0.5 * step;', '\t\t\t\t\t\t\t\tvec3 istep = step / float(REFINEMENT_STEPS);', '\t\t\t\t\t\t\t\tfor (int i=0; i<REFINEMENT_STEPS; i++) {', '\t\t\t\t\t\t\t\t\t\tval = sample1(iloc);', '\t\t\t\t\t\t\t\t\t\tif (val > u_renderthreshold) {', '\t\t\t\t\t\t\t\t\t\t\t\tgl_FragColor = add_lighting(val, iloc, dstep, view_ray);', '\t\t\t\t\t\t\t\t\t\t\t\treturn;', '\t\t\t\t\t\t\t\t\t\t}', '\t\t\t\t\t\t\t\t\t\tiloc += istep;', '\t\t\t\t\t\t\t\t}', '\t\t\t\t\t\t}', // Advance location deeper into the volume\n  '\t\t\t\t\t\tloc += step;', '\t\t\t\t}', '\t\t}', '\t\tvec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray)', '\t\t{', // Calculate color by incorporating lighting\n  // View direction\n  '\t\t\t\tvec3 V = normalize(view_ray);', // calculate normal vector from gradient\n  '\t\t\t\tvec3 N;', '\t\t\t\tfloat val1, val2;', '\t\t\t\tval1 = sample1(loc + vec3(-step[0], 0.0, 0.0));', '\t\t\t\tval2 = sample1(loc + vec3(+step[0], 0.0, 0.0));', '\t\t\t\tN[0] = val1 - val2;', '\t\t\t\tval = max(max(val1, val2), val);', '\t\t\t\tval1 = sample1(loc + vec3(0.0, -step[1], 0.0));', '\t\t\t\tval2 = sample1(loc + vec3(0.0, +step[1], 0.0));', '\t\t\t\tN[1] = val1 - val2;', '\t\t\t\tval = max(max(val1, val2), val);', '\t\t\t\tval1 = sample1(loc + vec3(0.0, 0.0, -step[2]));', '\t\t\t\tval2 = sample1(loc + vec3(0.0, 0.0, +step[2]));', '\t\t\t\tN[2] = val1 - val2;', '\t\t\t\tval = max(max(val1, val2), val);', '\t\t\t\tfloat gm = length(N); // gradient magnitude', '\t\t\t\tN = normalize(N);', // Flip normal so it points towards viewer\n  '\t\t\t\tfloat Nselect = float(dot(N, V) > 0.0);', '\t\t\t\tN = (2.0 * Nselect - 1.0) * N;\t// ==\tNselect * N - (1.0-Nselect)*N;', // Init colors\n  '\t\t\t\tvec4 ambient_color = vec4(0.0, 0.0, 0.0, 0.0);', '\t\t\t\tvec4 diffuse_color = vec4(0.0, 0.0, 0.0, 0.0);', '\t\t\t\tvec4 specular_color = vec4(0.0, 0.0, 0.0, 0.0);', // note: could allow multiple lights\n  '\t\t\t\tfor (int i=0; i<1; i++)', '\t\t\t\t{', // Get light direction (make sure to prevent zero devision)\n  '\t\t\t\t\t\tvec3 L = normalize(view_ray);\t//lightDirs[i];', '\t\t\t\t\t\tfloat lightEnabled = float( length(L) > 0.0 );', '\t\t\t\t\t\tL = normalize(L + (1.0 - lightEnabled));', // Calculate lighting properties\n  '\t\t\t\t\t\tfloat lambertTerm = clamp(dot(N, L), 0.0, 1.0);', '\t\t\t\t\t\tvec3 H = normalize(L+V); // Halfway vector', '\t\t\t\t\t\tfloat specularTerm = pow(max(dot(H, N), 0.0), shininess);', // Calculate mask\n  '\t\t\t\t\t\tfloat mask1 = lightEnabled;', // Calculate colors\n  '\t\t\t\t\t\tambient_color +=\tmask1 * ambient_color;\t// * gl_LightSource[i].ambient;', '\t\t\t\t\t\tdiffuse_color +=\tmask1 * lambertTerm;', '\t\t\t\t\t\tspecular_color += mask1 * specularTerm * specular_color;', '\t\t\t\t}', // Calculate final color by componing different components\n  '\t\t\t\tvec4 final_color;', '\t\t\t\tvec4 color = apply_colormap(val);', '\t\t\t\tfinal_color = color * (ambient_color + diffuse_color) + specular_color;', '\t\t\t\tfinal_color.a = color.a;', '\t\t\t\treturn final_color;', '\t\t}'].join('\\n')\n};\n\nexport { VolumeRenderShader1 };\n"]},"metadata":{},"sourceType":"module"}